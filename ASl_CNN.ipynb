{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d2ec1d-79c9-457d-860f-05224997a6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dfoda\\anaconda3\\envs\\ASLRecognition\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Не найдена указанная процедура'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import shutil\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51a85e-c78c-4efc-9c55-f4e8f6ee0754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1e620d-7250-4f68-9c94-2e64aad57805",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccf2865-e793-41e6-ab45-dac1d561f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3fbc72-1a04-4cf4-95ba-3f475bbf08c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb090963-7547-4924-aa32-25bcd211b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder('data/processed_images_hands_init/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa9a14-5453-43d6-b7ae-767fd89b1c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbbf327-70a5-4120-9187-108e2bb7c24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf18576-7192-4420-b432-58c73444df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be7af63-6d32-4a62-aeae-66d407d7140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbaa3a68-5dbc-459b-9146-35ca4468e6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Выбор одной картинки из batch\n",
    "image = images[0]\n",
    "label = labels[0]\n",
    "\n",
    "image = image.permute(1, 2, 0).numpy()  # Перемещение размерностей из (C, H, W) в (H, W, C)\n",
    "plt.imshow(image)\n",
    "plt.title(f'Label: {label.item()}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e932a501-26ef-4827-a8bb-4b8369233c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = 2\n",
    "stride_size = 1\n",
    "kernel_size = 3\n",
    "padding = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5836e09-643c-4211-9975-57b6b5bdf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignLanguageCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SignLanguageCNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=kernel_size, stride=stride_size, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=kernel_size, stride=stride_size, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=kernel_size, stride=stride_size, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.drop_out = nn.Dropout() \n",
    "        \n",
    "        self.fc1 = nn.Linear(4608, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc3 = nn.Linear(512, 29)\n",
    "\n",
    "    def forward(self, x): \n",
    "         out = self.layer1(x) \n",
    "         out = self.layer2(out) \n",
    "         out = self.layer3(out)\n",
    "         out = out.reshape(out.size(0), -1) \n",
    "         out = self.drop_out(out) \n",
    "         out = F.softmax(out, dim=1)\n",
    "         out = self.fc1(out) \n",
    "         out = self.fc2(out) \n",
    "         out = self.fc3(out) \n",
    "         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5b6f0b-45ee-4756-98ac-dba3fb3168ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'asl_cnn_best_model.pth')\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610c4b8-121d-401b-a272-c940c7a93625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413f2073-281a-469f-bef8-d3e2ce2280f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, train_loader, val_loader, optimizer, loss_fun, accuracy, device, early_stopping=False):\n",
    "    model.to(device)\n",
    "    \n",
    "    if early_stopping:\n",
    "        early_stopping = EarlyStopping(patience=40, verbose=True)\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        accuracy.reset()  # Reset metric at the beginning of each epoch\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\", total=len(train_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fun(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            accuracy.update(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        average_loss = running_loss / num_batches\n",
    "        epoch_accuracy = accuracy.compute()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_batches = 0\n",
    "        val_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\", total=len(val_loader)):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = loss_fun(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "                val_accuracy += torch.sum(torch.argmax(outputs, dim=1) == labels).item()\n",
    "        \n",
    "        average_val_loss = val_loss / val_batches\n",
    "        val_accuracy = val_accuracy / len(val_loader.dataset)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        if early_stopping:\n",
    "            early_stopping(average_val_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf24555-b178-49ff-947d-13ef034dbc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22530bc3-56e3-44fc-b8ff-6b942a007803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignLanguageCNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=4608, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=29, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SignLanguageCNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "501a90f0-4c9e-4e1a-9a34-0121dd6b2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "accuracy = torchmetrics.Accuracy(task='MULTICLASS', num_classes=29)\n",
    "accuracy.to(device)\n",
    "\n",
    "num_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75c973e7-cb12-496e-9705-f0abd2507ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/40: 100%|███████████████████████████████████████████████████████████| 902/902 [03:51<00:00,  3.89it/s]\n",
      "Validation Epoch 1/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:15<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 1.9230, Accuracy: 0.4370, Val Loss: 1.4142, Val Accuracy: 0.5470\n",
      "Validation loss decreased (inf --> 1.414205).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/40: 100%|███████████████████████████████████████████████████████████| 902/902 [04:12<00:00,  3.57it/s]\n",
      "Validation Epoch 2/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:08<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40], Loss: 0.8842, Accuracy: 0.7337, Val Loss: 1.4281, Val Accuracy: 0.5451\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/40: 100%|███████████████████████████████████████████████████████████| 902/902 [04:05<00:00,  3.68it/s]\n",
      "Validation Epoch 3/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:12<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/40], Loss: 0.7298, Accuracy: 0.7899, Val Loss: 0.7693, Val Accuracy: 0.7440\n",
      "Validation loss decreased (1.414205 --> 0.769342).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/40: 100%|███████████████████████████████████████████████████████████| 902/902 [04:01<00:00,  3.73it/s]\n",
      "Validation Epoch 4/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:21<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40], Loss: 1.0593, Accuracy: 0.8028, Val Loss: 27.4002, Val Accuracy: 0.0755\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/40: 100%|███████████████████████████████████████████████████████████| 902/902 [04:15<00:00,  3.53it/s]\n",
      "Validation Epoch 5/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:19<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40], Loss: 0.9990, Accuracy: 0.8530, Val Loss: 0.5986, Val Accuracy: 0.8063\n",
      "Validation loss decreased (0.769342 --> 0.598632).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/40: 100%|███████████████████████████████████████████████████████████| 902/902 [04:12<00:00,  3.57it/s]\n",
      "Validation Epoch 6/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:15<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40], Loss: 0.3362, Accuracy: 0.9034, Val Loss: 0.6166, Val Accuracy: 0.8038\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/40: 100%|███████████████████████████████████████████████████████████| 902/902 [04:18<00:00,  3.49it/s]\n",
      "Validation Epoch 7/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:27<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/40], Loss: 0.3540, Accuracy: 0.8997, Val Loss: 0.9138, Val Accuracy: 0.7067\n",
      "EarlyStopping counter: 2 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/40: 100%|███████████████████████████████████████████████████████████| 902/902 [05:12<00:00,  2.89it/s]\n",
      "Validation Epoch 8/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:25<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/40], Loss: 0.9331, Accuracy: 0.8458, Val Loss: 0.5799, Val Accuracy: 0.8143\n",
      "Validation loss decreased (0.598632 --> 0.579902).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/40: 100%|███████████████████████████████████████████████████████████| 902/902 [05:09<00:00,  2.91it/s]\n",
      "Validation Epoch 9/40: 100%|█████████████████████████████████████████████████████████| 226/226 [01:24<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/40], Loss: 0.3224, Accuracy: 0.9131, Val Loss: 1.1087, Val Accuracy: 0.6426\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:08<00:00,  2.93it/s]\n",
      "Validation Epoch 10/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:21<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40], Loss: 2.2490, Accuracy: 0.8559, Val Loss: 7.9167, Val Accuracy: 0.5314\n",
      "EarlyStopping counter: 2 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/40: 100%|██████████████████████████████████████████████████████████| 902/902 [04:56<00:00,  3.04it/s]\n",
      "Validation Epoch 11/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:29<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/40], Loss: 0.7520, Accuracy: 0.8991, Val Loss: 1.1429, Val Accuracy: 0.6807\n",
      "EarlyStopping counter: 3 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/40: 100%|██████████████████████████████████████████████████████████| 902/902 [04:58<00:00,  3.02it/s]\n",
      "Validation Epoch 12/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:22<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/40], Loss: 0.3356, Accuracy: 0.9183, Val Loss: 0.6219, Val Accuracy: 0.8095\n",
      "EarlyStopping counter: 4 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:14<00:00,  2.87it/s]\n",
      "Validation Epoch 13/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:28<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/40], Loss: 0.3068, Accuracy: 0.9212, Val Loss: 1.0406, Val Accuracy: 0.6803\n",
      "EarlyStopping counter: 5 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:33<00:00,  2.70it/s]\n",
      "Validation Epoch 14/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:47<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/40], Loss: 0.3057, Accuracy: 0.9185, Val Loss: 0.9390, Val Accuracy: 0.7371\n",
      "EarlyStopping counter: 6 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/40: 100%|██████████████████████████████████████████████████████████| 902/902 [06:00<00:00,  2.50it/s]\n",
      "Validation Epoch 15/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:43<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/40], Loss: 1.7038, Accuracy: 0.8583, Val Loss: 0.9583, Val Accuracy: 0.8031\n",
      "EarlyStopping counter: 7 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:52<00:00,  2.56it/s]\n",
      "Validation Epoch 16/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:24<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/40], Loss: 0.3781, Accuracy: 0.9192, Val Loss: 0.4831, Val Accuracy: 0.8719\n",
      "Validation loss decreased (0.579902 --> 0.483056).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:13<00:00,  2.88it/s]\n",
      "Validation Epoch 17/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:26<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/40], Loss: 0.3005, Accuracy: 0.9238, Val Loss: 0.6075, Val Accuracy: 0.8228\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:23<00:00,  2.79it/s]\n",
      "Validation Epoch 18/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:29<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/40], Loss: 0.3244, Accuracy: 0.9169, Val Loss: 0.5473, Val Accuracy: 0.8316\n",
      "EarlyStopping counter: 2 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:42<00:00,  2.63it/s]\n",
      "Validation Epoch 19/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:24<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/40], Loss: 2.5345, Accuracy: 0.8558, Val Loss: 1.3452, Val Accuracy: 0.7219\n",
      "EarlyStopping counter: 3 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:05<00:00,  2.96it/s]\n",
      "Validation Epoch 20/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:23<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40], Loss: 0.4475, Accuracy: 0.9138, Val Loss: 0.4715, Val Accuracy: 0.8462\n",
      "Validation loss decreased (0.483056 --> 0.471545).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:07<00:00,  2.93it/s]\n",
      "Validation Epoch 21/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:23<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/40], Loss: 0.3312, Accuracy: 0.9209, Val Loss: 0.4864, Val Accuracy: 0.8665\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:18<00:00,  2.83it/s]\n",
      "Validation Epoch 22/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:27<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/40], Loss: 0.3092, Accuracy: 0.9243, Val Loss: 0.6505, Val Accuracy: 0.7911\n",
      "EarlyStopping counter: 2 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:23<00:00,  2.79it/s]\n",
      "Validation Epoch 23/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:33<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/40], Loss: 0.3827, Accuracy: 0.9120, Val Loss: 1.8336, Val Accuracy: 0.6068\n",
      "EarlyStopping counter: 3 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:07<00:00,  2.93it/s]\n",
      "Validation Epoch 24/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:10<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/40], Loss: 2.1799, Accuracy: 0.8602, Val Loss: 0.3341, Val Accuracy: 0.9190\n",
      "Validation loss decreased (0.471545 --> 0.334064).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/40: 100%|██████████████████████████████████████████████████████████| 902/902 [04:17<00:00,  3.51it/s]\n",
      "Validation Epoch 25/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:22<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/40], Loss: 0.3285, Accuracy: 0.9278, Val Loss: 0.4934, Val Accuracy: 0.8686\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:15<00:00,  2.86it/s]\n",
      "Validation Epoch 26/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:17<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/40], Loss: 0.3000, Accuracy: 0.9295, Val Loss: 0.7252, Val Accuracy: 0.8285\n",
      "EarlyStopping counter: 2 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:17<00:00,  2.85it/s]\n",
      "Validation Epoch 27/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:33<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/40], Loss: 0.3034, Accuracy: 0.9259, Val Loss: 0.7675, Val Accuracy: 0.7692\n",
      "EarlyStopping counter: 3 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:48<00:00,  2.59it/s]\n",
      "Validation Epoch 28/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:29<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/40], Loss: 1.7590, Accuracy: 0.8748, Val Loss: 1.2591, Val Accuracy: 0.8109\n",
      "EarlyStopping counter: 4 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:49<00:00,  2.58it/s]\n",
      "Validation Epoch 29/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:26<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/40], Loss: 0.4948, Accuracy: 0.9205, Val Loss: 0.5141, Val Accuracy: 0.8663\n",
      "EarlyStopping counter: 5 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:12<00:00,  2.89it/s]\n",
      "Validation Epoch 30/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:36<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/40], Loss: 0.3199, Accuracy: 0.9297, Val Loss: 0.7043, Val Accuracy: 0.8154\n",
      "EarlyStopping counter: 6 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/40: 100%|██████████████████████████████████████████████████████████| 902/902 [05:12<00:00,  2.89it/s]\n",
      "Validation Epoch 31/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:30<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/40], Loss: 0.3349, Accuracy: 0.9244, Val Loss: 16.2277, Val Accuracy: 0.0902\n",
      "EarlyStopping counter: 7 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/40: 100%|██████████████████████████████████████████████████████████| 902/902 [06:14<00:00,  2.41it/s]\n",
      "Validation Epoch 32/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:47<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/40], Loss: 1.7364, Accuracy: 0.8860, Val Loss: 1.1810, Val Accuracy: 0.7513\n",
      "EarlyStopping counter: 8 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/40: 100%|██████████████████████████████████████████████████████████| 902/902 [06:27<00:00,  2.33it/s]\n",
      "Validation Epoch 33/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:46<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/40], Loss: 0.3622, Accuracy: 0.9281, Val Loss: 0.7741, Val Accuracy: 0.7906\n",
      "EarlyStopping counter: 9 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/40: 100%|██████████████████████████████████████████████████████████| 902/902 [06:09<00:00,  2.44it/s]\n",
      "Validation Epoch 34/40: 100%|████████████████████████████████████████████████████████| 226/226 [02:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/40], Loss: 0.3111, Accuracy: 0.9300, Val Loss: 0.5922, Val Accuracy: 0.8195\n",
      "EarlyStopping counter: 10 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/40: 100%|██████████████████████████████████████████████████████████| 902/902 [06:00<00:00,  2.50it/s]\n",
      "Validation Epoch 35/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:35<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/40], Loss: 0.8570, Accuracy: 0.8876, Val Loss: 7.4259, Val Accuracy: 0.4984\n",
      "EarlyStopping counter: 11 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/40: 100%|██████████████████████████████████████████████████████████| 902/902 [04:42<00:00,  3.19it/s]\n",
      "Validation Epoch 36/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:22<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/40], Loss: 1.5307, Accuracy: 0.8982, Val Loss: 0.6636, Val Accuracy: 0.8493\n",
      "EarlyStopping counter: 12 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/40: 100%|██████████████████████████████████████████████████████████| 902/902 [04:39<00:00,  3.23it/s]\n",
      "Validation Epoch 37/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:20<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/40], Loss: 0.3404, Accuracy: 0.9336, Val Loss: 0.2815, Val Accuracy: 0.9249\n",
      "Validation loss decreased (0.334064 --> 0.281486).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/40: 100%|██████████████████████████████████████████████████████████| 902/902 [04:39<00:00,  3.23it/s]\n",
      "Validation Epoch 38/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:20<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/40], Loss: 0.3335, Accuracy: 0.9295, Val Loss: 0.6013, Val Accuracy: 0.8173\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/40: 100%|██████████████████████████████████████████████████████████| 902/902 [04:38<00:00,  3.23it/s]\n",
      "Validation Epoch 39/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:22<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/40], Loss: 1.7413, Accuracy: 0.8811, Val Loss: 0.9756, Val Accuracy: 0.8649\n",
      "EarlyStopping counter: 2 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40/40: 100%|██████████████████████████████████████████████████████████| 902/902 [04:24<00:00,  3.42it/s]\n",
      "Validation Epoch 40/40: 100%|████████████████████████████████████████████████████████| 226/226 [01:15<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/40], Loss: 0.5168, Accuracy: 0.9271, Val Loss: 0.8096, Val Accuracy: 0.7766\n",
      "EarlyStopping counter: 3 out of 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, num_epochs, train_loader, val_loader, optimizer, criterion, accuracy, device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec4de35-91d5-4edb-8605-f1c2c557f48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('asl_cnn_best_model_valacc-92-49.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e2113eb-57c6-4028-b174-52411c9b0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_class(model, image, class_names):\n",
    "    model.eval()\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return class_names[predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c67e847-401e-4299-8dab-f95cf1d99077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_for_prediction(image):\n",
    "    tensor_image = torch.tensor(image, dtype=torch.float32)\n",
    "    tensor_image = tensor_image.permute(2, 0, 1).unsqueeze(0)\n",
    "    return tensor_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3207e26-5cb5-40c2-bc69-939ca5350435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hand(image, hands, padding=20, target_size=(300, 300), bg_color=(128, 128, 128)):\n",
    "    rgb_image = image\n",
    "    rgb_image.flags.writeable = False\n",
    "\n",
    "    results = hands.process(rgb_image)\n",
    "\n",
    "    rgb_image.flags.writeable = True\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            h, w, _ = image.shape\n",
    "            x_min, y_min = w, h\n",
    "            x_max, y_max = 0, 0\n",
    "\n",
    "            landmarks = []\n",
    "\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "                x_min = min(x_min, x)\n",
    "                y_min = min(y_min, y)\n",
    "                x_max = max(x_max, x)\n",
    "                y_max = max(y_max, y)\n",
    "                landmarks.append((x, y, landmark.z))\n",
    "\n",
    "            x_min = max(0, x_min - padding)\n",
    "            y_min = max(0, y_min - padding)\n",
    "            x_max = min(w, x_max + padding)\n",
    "            y_max = min(h, y_max + padding)\n",
    "\n",
    "            hand_image = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            hand_h, hand_w, _ = hand_image.shape\n",
    "            scale = min(target_size[0] / hand_w, target_size[1] / hand_h)\n",
    "            new_w = int(hand_w * scale)\n",
    "            new_h = int(hand_h * scale)\n",
    "            resized_hand_image = cv2.resize(hand_image, (new_w, new_h))\n",
    "\n",
    "            result_image = np.full((target_size[1], target_size[0], 3), bg_color, dtype=np.uint8)\n",
    "            x_offset = (target_size[0] - new_w) // 2\n",
    "            y_offset = (target_size[1] - new_h) // 2\n",
    "            result_image[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized_hand_image\n",
    "\n",
    "            return result_image, results, (x_min, y_min, scale, x_offset, y_offset), landmarks\n",
    "    return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f9dcaf8-dd61-4376-9760-0b355ebc6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_camera(model, hands):\n",
    "    total_images = 0\n",
    "    total_time = 0\n",
    "    while True:\n",
    "        success, image = cap.read()\n",
    "        image = cv2.flip(image, 1)\n",
    "        imageRGB = image\n",
    "        \n",
    "        hand_pattern, results, bbox_params, original_landmarks = detect_hand(image, hands)\n",
    "        if results:\n",
    "            for handLms in results.multi_hand_landmarks:\n",
    "                draw.draw_landmarks(image, handLms, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "\n",
    "                x = int(handLms.landmark[0].x * image.shape[1])\n",
    "                y = int(handLms.landmark[0].y * image.shape[0])\n",
    "        \n",
    "        if hand_pattern is not None:\n",
    "            imageRGB = cv2.resize(hand_pattern, (SIZE, SIZE))\n",
    "        else:\n",
    "            imageRGB = cv2.resize(imageRGB, (SIZE, SIZE))\n",
    "\n",
    "        if results:\n",
    "            if results.multi_hand_landmarks:\n",
    "                for handLms in results.multi_hand_landmarks:\n",
    "                    draw.draw_landmarks(image, handLms, mp.solutions.hands.HAND_CONNECTIONS)\n",
    "                    tensor_image = process_image_for_prediction(imageRGB)\n",
    "                    time_s = time.time()\n",
    "                    predicted_class = predict_image_class(model, tensor_image, class_names)\n",
    "                    total_time += time.time() - time_s\n",
    "                    total_images += 1\n",
    "                    dynamic_console_output(f\"Predicted class: {predicted_class}\")\n",
    "                    cv2.putText(image, predicted_class, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (224, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        image_out = image\n",
    "        if hand_pattern is not None:\n",
    "            hand_cam = cv2.resize(hand_pattern, (150, 150))\n",
    "        else:\n",
    "            hand_cam = cv2.resize(image, (150, 150))\n",
    "        height, width, _ = hand_cam.shape\n",
    "        height_out, width_out, _ = image_out.shape\n",
    "    \n",
    "        x_offset = width_out - width\n",
    "        y_offset = 0\n",
    "        \n",
    "        image_out[y_offset:y_offset+height, x_offset:x_offset+width] = hand_cam\n",
    "\n",
    "        cv2.imshow('Hand', image_out)\n",
    "        \n",
    "        if cv2.waitKey(33) != -1:\n",
    "            cv2.destroyAllWindows()\n",
    "            # break\n",
    "            return total_time / total_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "359425e2-8082-45ba-9005-9ff7e019849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_console_output(log):\n",
    "    # Получаем текущую ширину строки терминала\n",
    "    terminal_width = shutil.get_terminal_size().columns\n",
    "\n",
    "    # Обрезаем предыдущий лог до текущей ширины строки\n",
    "    log = log.ljust(terminal_width)\n",
    "    \n",
    "    # Выводим новый лог\n",
    "    sys.stdout.write(\"\\r\\033[K\" + log)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "569533ca-b40a-423b-a035-8c1206fe2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "hands = mp.solutions.hands.Hands(max_num_hands=2)\n",
    "draw = mp.solutions.drawing_utils\n",
    "\n",
    "class_names = dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47ec131d-b33d-42fc-b7ae-c26b19be006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dfoda\\anaconda3\\envs\\ASLRecognition\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KPredicted class: X                                                                                                      "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011310779530069103"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_camera(model, hands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92a93e18-08d6-4451-b76d-e832426da17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "836de217-c814-417f-9ee5-c5905d33f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images_in_folder(folder_path, model):\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    subfolders = [f.path for f in os.scandir(folder_path) if f.is_dir()]\n",
    "    \n",
    "    for subfolder in subfolders:\n",
    "        class_name = os.path.basename(subfolder)\n",
    "        print(f'Processing images in class: {class_name}')\n",
    "     \n",
    "        files = [f for f in os.listdir(subfolder) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "        \n",
    "        for file in files:\n",
    "            image_path = os.path.join(subfolder, file)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            hand_pattern, results_pattern, bbox_params, original_landmarks = detect_hand(image, hands)\n",
    "            if hand_pattern is not None:\n",
    "                imageRGB = cv2.resize(hand_pattern, (SIZE, SIZE))\n",
    "            else:\n",
    "                imageRGB = cv2.resize(imageRGB, (SIZE, SIZE))\n",
    "            if results_pattern:\n",
    "                if results_pattern.multi_hand_landmarks:\n",
    "                    tensor_image = process_image_for_prediction(imageRGB)\n",
    "                    predicted_class = predict_image_class(model, tensor_image, class_names)\n",
    "                else:\n",
    "                    predicted_class = 'nothing'\n",
    "            else:\n",
    "                predicted_class = 'nothing'\n",
    "            predictions.append(predicted_class)\n",
    "            true_labels.append(class_name)\n",
    "            \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f94acaaa-c235-4a75-9b16-d939716ce202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images in class: A\n",
      "Processing images in class: B\n",
      "Processing images in class: C\n",
      "Processing images in class: D\n",
      "Processing images in class: del\n",
      "Processing images in class: E\n",
      "Processing images in class: F\n",
      "Processing images in class: G\n",
      "Processing images in class: H\n",
      "Processing images in class: I\n",
      "Processing images in class: J\n",
      "Processing images in class: K\n",
      "Processing images in class: L\n",
      "Processing images in class: M\n",
      "Processing images in class: N\n",
      "Processing images in class: nothing\n",
      "Processing images in class: O\n",
      "Processing images in class: P\n",
      "Processing images in class: Q\n",
      "Processing images in class: R\n",
      "Processing images in class: S\n",
      "Processing images in class: space\n",
      "Processing images in class: T\n",
      "Processing images in class: U\n",
      "Processing images in class: V\n",
      "Processing images in class: W\n",
      "Processing images in class: X\n",
      "Processing images in class: Y\n",
      "Processing images in class: Z\n",
      "Accuracy: 0.06896551724137931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "path = 'data/test_images'\n",
    "predict_images_in_folder(path, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
